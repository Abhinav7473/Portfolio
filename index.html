<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Abhinav Balakrishnan</title>
    <meta name="description" content="Research and analysis at the intersection of technical success and practical failure.">

    <!-- Favicon -->
    <link
        rel="icon"
        type="image/svg+xml"
        href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ccircle cx='50' cy='50' r='10' fill='%231A1A1A'/%3E%3C/svg%3E"
    >

    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
</head>
<body>
    <main>
        <header>
            <h1>Abhinav Balakrishnan</h1>
            <p class="lens">I'm interested in the point where systems technically succeed and practically fail.</p>
        </header>

        <section class="intro">
            <p>Most systems don't break in obvious ways. They degrade. They return correct outputs in the wrong sequence, present confidence where uncertainty would be more honest, and discourage exploration by making deviation expensive. I tend to notice hesitation. When someone pauses, rereads, or second-guesses an interface they were supposed to trust. That pause usually isn't user error. It's a signal.</p>
        </section>

        <section class="projects-grid">
            <article class="project-card" style="--delay: 0ms">
                <div class="project-header">
                    <h2>RT-MTCP: Real-Time Multi-Target Traffic Crash Prediction</h2>
                    <span class="project-tag">Urban Planning</span>
                </div>
                
                <div class="context">
                    <p>Urban crash prediction models are typically optimized for aggregate accuracy, implicitly treating all errors as equally costly. In practice, they aren't.</p>
                </div>

                <div class="breakdown">
                    <h3>Failure mode</h3>
                    <p>Under extreme class imbalance, existing models performed well on global metrics while underrepresenting low-frequency, high-impact crashes. These cases were statistically minor but operationally significant, producing stable scores while obscuring scenarios planners are most sensitive to.</p>
                </div>

                <div class="breakdown">
                    <h3>Intervention</h3>
                    <p>I reoriented the modeling and evaluation pipeline toward reliability under stress rather than mean performance. Emphasis shifted to minority-class recall, with gradient boosting and Bayesian smoothing used to retain rare patterns instead of averaging them away. Evaluation was structured to surface failure cases rather than absorb them into aggregate scores.</p>
                </div>

                <div class="breakdown">
                    <h3>Result</h3>
                    <p>Minority-class recall increased by 22–37%. The resulting signals were less stable on paper but better aligned with how risk is interpreted in downstream planning and emergency-response contexts.</p>
                    
                    <figure class="project-figure">
                        <img src="rtmtcp-architecture.png" alt="RT-MTCP system architecture" class="project-image">
                        <figcaption>End-to-end pipeline showing data splitting, feature engineering, multi-architecture validation, and transfer learning approach for handling pandemic-era distribution shift.</figcaption>
                    </figure>
                </div>
            </article>

            <article class="project-card" style="--delay: 80ms">
                <div class="project-header">
                    <h2>AI Support Platform at Softeon</h2>
                    <span class="project-tag">Enterprise Software</span>
                </div>
                
                <div class="context">
                    <p>Enterprise support agents operate under time pressure, partial information, and shifting priorities. Many support tools respond by exposing more data, assuming volume compensates for clarity.</p>
                </div>

                <div class="breakdown">
                    <h3>Failure mode</h3>
                    <p>Early versions surfaced correct information too late and without regard for role or context. Latency and dense outputs increased hesitation, misinterpretation, and unnecessary escalation. The issue wasn't correctness. It was timing and framing.</p>
                </div>

                <div class="breakdown">
                    <h3>Intervention</h3>
                    <p>The interaction flow was redesigned around progressive disclosure. High-confidence knowledge surfaced first, followed by historical context. Dashboards were separated by role after observing how shared metrics were consistently misread. Even configuration controls were exposed so behavior could be adjusted without engineering involvement.</p>
                </div>

                <div class="breakdown">
                    <h3>Result</h3>
                    <p>The platform was adopted into daily workflows by 50+ users. Quality ratings improved from 88% to 98.6% over time, largely through iterative adjustments driven by a set of observed breakdowns rather than feature expansion.</p>
                    
                    <figure class="project-figure">
                        <img src="softeon-dashboard.png" alt="Softeon analytics dashboard" class="project-image">
                        <figcaption>Role-specific analytics interface showing aggregated metrics for ticket resolution patterns (proprietary client data redacted).</figcaption>
                    </figure>
                </div>
            </article>

            <article class="project-card" style="--delay: 160ms">
                <div class="project-header">
                    <h2>CAN Intrusion Detection System</h2>
                    <span class="project-tag">Automotive Security</span>
                </div>

                <div class="context">
                    <p>Automotive intrusion detection tends to output binary judgments and a single confidence score. That’s convenient until different detectors disagree and there’s no way to resolve which signal to trust.</p>
                </div>

                <div class="breakdown">
                    <h3>Failure mode</h3>
                    <p>Three detectors, three tempos. One flags immediately. Another needs a short sequence to decide. A third is tuned to a different timescale. Operators saw contradictions with no explanation and were forced to guess which to follow. The incentives favored quick dismissals over careful inquiry.</p>
                </div>

                <div class="breakdown">
                    <h3>Intervention</h3>
                    <p>I treated disagreement as data. The UI surfaced model disagreement and per-signal feature attributions so operators could see which sensors moved and why. Threshold adjustments became interactive, not code-bound. A lightweight 3D view exposed spatial clustering that tables hid. Interaction logging captured which explanations were inspected and which were ignored.</p>
                </div>

                <div class="breakdown">
                    <h3>Result</h3>
                    <p>Two-of-three detectors disagreed ~40% of the time. That created natural decision points where operator reasoning could be observed and audited. The system made the uncertainty legible, which is the only defensible move when models disagree.</p>

                    <figure class="project-figure">
                        <img src="CAN.png" alt="CAN intrusion detection comparative analysis" class="project-image">
                        <figcaption>Multi-model comparison interface showing SVM, LSTM, and specialized detectors on matching sensor data, with disagreement highlighting and feature attributions.</figcaption>
                    </figure>
                </div>
            </article>

            <article class="project-card" style="--delay: 240ms">
                <div class="project-header">
                    <h2>Warehouse Management System with 3D Visualization</h2>
                    <span class="project-tag">Logistics</span>
                </div>
                
                <div class="context">
                    <p>Conventional WMS interfaces require operators to reconstruct physical space from tables, filters, and static diagrams. This works when time pressure is low. It doesn't scale to live operations.</p>
                </div>

                <div class="breakdown">
                    <h3>Failure mode</h3>
                    <p>Critical decisions depended on abstract representations that made spatial reasoning slow and error-prone, particularly in dense storage environments. Operators spent effort translating views instead of acting.</p>
                </div>

                <div class="breakdown">
                    <h3>Intervention</h3>
                    <p>I built a 3D digital twin using ArUco-based physical–digital synchronization, allowing the warehouse to be navigated as a continuous space. Real-time APIs and path optimization reduced context switching during active picking rather than adding another layer of abstraction.</p>
                </div>

                <div class="breakdown">
                    <h3>Result</h3>
                    <p>Picker travel distance decreased by 12–18%. Spatial decisions became faster without introducing additional training overhead.</p>
                    
                    <figure class="project-figure">
                        <img src="warehouse-3d.png" alt="Warehouse 3D visualization" class="project-image">
                        <figcaption>Spatial navigation interface showing high-density storage layout with real-time ArUco marker synchronization for physical-digital coordination.</figcaption>
                    </figure>
                </div>
            </article>
        </section>

        <footer>
            <a href="https://github.com/Abhinav7473" target="_blank" rel="noopener">GitHub</a>
            <span class="separator">•</span>
            <a href="Abhinav-Resume.pdf" target="_blank" rel="noopener">Resume</a>
            <span class="separator">•</span>
            <a href="mailto:abhikrish734@gmail.com">abhikrish734@gmail.com</a>
        </footer>
    </main>
    <script>
        const observer = new IntersectionObserver(
            (entries) => entries.forEach(e => {
                if (e.isIntersecting) { e.target.classList.add('visible'); observer.unobserve(e.target); }
            }),
            { threshold: 0.08 }
        );
        document.querySelectorAll('.project-card').forEach(c => observer.observe(c));
    </script>
</body>
</html>